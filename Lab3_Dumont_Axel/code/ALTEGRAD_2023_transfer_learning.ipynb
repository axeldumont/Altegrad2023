{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DlAfI8mCWAf3"
      },
      "source": [
        "<center><h2>ALTeGraD 2023<br>Lab Session 3: Transfer learning for NLP</h2> 24 / 10 / 2023<br> Dr. G. Shang, H. Abdine<br><br>\n",
        "\n",
        "\n",
        "<b>Student name:</b> Axel Dumont\n",
        "\n",
        "</center>\n",
        "\n",
        "<br><br>\n",
        "In this lab we will:\n",
        "* Implement and pretrain a language model with transformer architecture.\n",
        "* Use the pretrained model (transfer learning) to perform a sentiment analysis task which consists of classifying some books reviews into positive and negative ones.\n",
        "* Compare the performance of the pretrained model to a model trained from scratch.\n",
        " <br>\n",
        "\n",
        "<b>The deadline for this lab is October 31, 2023 11:59 PM.</b> More details about the submission and the architecture for this lab can be found in the handout PDF."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "IqukuIe0Rb_c"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5FF6fjkqgN39"
      },
      "source": [
        "### The Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "kt2QQohaFZry"
      },
      "outputs": [],
      "source": [
        "class PositionalEncoding(nn.Module):\n",
        "    def __init__(self, nhid, dropout=0.1, max_len=5000):\n",
        "        super(PositionalEncoding, self).__init__()\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        pe = torch.zeros(max_len, nhid)\n",
        "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
        "        div_term = torch.exp(\n",
        "            torch.arange(0, nhid, 2).float() * (-math.log(10000.0) / nhid)\n",
        "        )\n",
        "        pe[:, 0::2] = torch.sin(position * div_term)\n",
        "        pe[:, 1::2] = torch.cos(position * div_term)\n",
        "        pe = pe.unsqueeze(0).transpose(0, 1)\n",
        "        self.register_buffer(\"pe\", pe)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.pe[: x.size(0), :]\n",
        "        return self.dropout(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "p0cj9WkSFQwl"
      },
      "outputs": [],
      "source": [
        "class TransformerModel(nn.Module):\n",
        "    def __init__(self, ntoken, nhead, nhid, nlayers, dropout=0.5):\n",
        "        super(TransformerModel, self).__init__()\n",
        "        '''\n",
        "        ntokens: the size of vocabulary\n",
        "        nhid: the hidden dimension of the model.\n",
        "        We assume that embedding_dim = nhid\n",
        "        nlayers: the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
        "        nhead: the number of heads in the multiheadattention models\n",
        "        dropout: the dropout value\n",
        "         '''\n",
        "        self.model_type = \"Transformer\"\n",
        "        self.encoder = nn.Embedding(ntoken, nhid) # fill me, nhid = the dim_embed\n",
        "        self.pos_encoder = PositionalEncoding(nhid, dropout) #fill me, the PositionalEncoding class is implemented in the next cell\n",
        "        encoder_layers = nn.TransformerEncoderLayer(nhid, nhead, nhid, dropout) #fill me we assume nhid = d_model = dim_feedforward\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layers, nlayers) #fill me\n",
        "        self.nhid = nhid\n",
        "        self.init_weights()\n",
        "\n",
        "    def generate_square_subsequent_mask(self, sz):\n",
        "        mask = (torch.triu(torch.ones(sz, sz)) == 1).transpose(0, 1)\n",
        "        mask = (\n",
        "            mask.float()\n",
        "            .masked_fill(mask == 0, float(\"-inf\"))\n",
        "            .masked_fill(mask == 1, float(0.0))\n",
        "        )\n",
        "        return mask\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.1\n",
        "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "    def forward(self, src, src_mask):\n",
        "        src = self.encoder(src) * math.sqrt(self.nhid)\n",
        "        src = self.pos_encoder(src)\n",
        "        output = self.transformer_encoder(src, src_mask)\n",
        "        return output\n",
        "\n",
        "\n",
        "class ClassificationHead(nn.Module):\n",
        "    def __init__(self, nhid, nclasses):\n",
        "        super(ClassificationHead, self).__init__()\n",
        "        self.decoder = nn.Linear(nhid, nclasses)\n",
        "        self.init_weights()\n",
        "\n",
        "    def init_weights(self):\n",
        "        initrange = 0.1\n",
        "        self.decoder.bias.data.zero_()\n",
        "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
        "\n",
        "    def forward(self, src):\n",
        "        output = self.decoder(src)\n",
        "        return output\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, ntoken, nhead, nhid, nlayers, nclasses, dropout=0.5):\n",
        "        super(Model, self).__init__()\n",
        "        self.base = TransformerModel(ntoken, nhead, nhid, nlayers, dropout)\n",
        "        self.classifier = ClassificationHead(nhid, nclasses)\n",
        "\n",
        "    def forward(self, src, src_mask):\n",
        "        # base model\n",
        "        x = self.base(src, src_mask)\n",
        "        # classifier model\n",
        "        output = self.classifier(x)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfEYHJx2JW6l"
      },
      "source": [
        "Let's verify if our model works, by applying one inference step"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "rhb2gkUhJMR0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bdfed7c4-897b-418b-babf-5d5038d91043"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 6, 100])\n",
            "Number of trainable parameters: 1008100\n",
            "Parameters: 1.2895546076778097\n"
          ]
        }
      ],
      "source": [
        "ntokens = 100 # the size of vocabulary\n",
        "nhid = 200  # hidden dimension\n",
        "nlayers = 4  # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
        "nhead = 2  # the number of heads in the multiheadattention models\n",
        "dropout = 0  # the dropout value\n",
        "\n",
        "model = Model(ntokens, nhead, nhid, nlayers, ntokens, dropout).to(device)\n",
        "dummy_input = torch.tensor([[2, 6, 2, 5, 43, 21]]).to(device)\n",
        "src_mask = model.base.generate_square_subsequent_mask(1).to(device)\n",
        "out = model.forward(dummy_input, src_mask)\n",
        "\n",
        "print(out.shape) # is it the right shape?\n",
        "num_params = sum(p.numel() for p in model.parameters())\n",
        "print(f\"Number of trainable parameters: {num_params}\")\n",
        "\n",
        "Parameters=(ntokens*nhid) + (3*(nhid**2)*nhead + 2*(nhid**2))*nlayers\n",
        "print(f\"Parameters: {Parameters/num_params}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i74NN897Fcit"
      },
      "source": [
        "## Vocabulary and Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "5qjd26ghWuff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8036180f-1a9f-4ad0-ebdb-833503770665"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-10-31 18:03:09--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/dict.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 577587 (564K) [text/plain]\n",
            "Saving to: ‘dict.txt.7’\n",
            "\n",
            "dict.txt.7          100%[===================>] 564.05K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2023-10-31 18:03:10 (29.2 MB/s) - ‘dict.txt.7’ saved [577587/577587]\n",
            "\n",
            "▁d 1\n",
            "es 1\n",
            "▁l 1\n",
            "en 1\n",
            "on 1\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/dict.txt\n",
        "!head -5 dict.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "vFdH_-JeFbGA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20c82f0e-7b9f-40b5-ca63-958bd0cab2dc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "49997\n",
            "▁trop\n"
          ]
        }
      ],
      "source": [
        "path_vocab = \"dict.txt\"\n",
        "token2ind = {\"<sos>\": 0, \"<pad>\": 1, \"<eos>\": 2, \"<oov>\": 3} # the 4 first indices are reserved to special tokens\n",
        "num_token = 0\n",
        "with open(path_vocab, \"r\") as f:\n",
        "    for idx, line in enumerate(f):\n",
        "        word = line.split()[0].strip()\n",
        "        token2ind[word] =  idx + 4\n",
        "        num_token += 1\n",
        "\n",
        "ind2token = {ind: token for token, ind in token2ind.items()}\n",
        "print(num_token)\n",
        "print(ind2token[1111])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOExGODajN8p"
      },
      "source": [
        "### Data Loader\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Y0jN-Ar9i5Q1"
      },
      "outputs": [],
      "source": [
        "import numpy\n",
        "import torch\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "\n",
        "\n",
        "class Dataset(Dataset):\n",
        "    def __init__(\n",
        "        self,\n",
        "        path_documents,\n",
        "        path_labels=None,\n",
        "        token2ind={},\n",
        "        max_len=512,\n",
        "        task=\"language_modeling\",\n",
        "    ):\n",
        "        self.task = task\n",
        "        self.max_len = max_len\n",
        "        self.token2ind = token2ind\n",
        "        self.documents = []\n",
        "        self.labels = []\n",
        "        with open(path_documents, \"r\") as f1:\n",
        "            for line in f1:\n",
        "                self.documents.append(line.strip())\n",
        "        if task == \"classification\":\n",
        "            with open(path_labels, \"r\") as f1:\n",
        "                for line in f1:\n",
        "                    self.labels.append(int(line.strip()))\n",
        "            assert len(self.labels) == len(self.documents)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.documents)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        sequence = self.documents[index].split()\n",
        "        if len(sequence) > self.max_len - 1:\n",
        "            sequence = sequence[: self.max_len - 1]\n",
        "        source_sequence = [self.token2ind[\"<sos>\"]] + [self.token2ind.get(token, self.token2ind[\"<oov>\"]) for token in sequence] #fill me (constract the input sequence using token2ind, sequence and special tokens)\n",
        "        if self.task == \"language_modeling\":\n",
        "            target = source_sequence[1:]\n",
        "            target.append(self.token2ind[\"<eos>\"])\n",
        "        elif self.task == \"classification\":\n",
        "            target = [self.labels[index]]\n",
        "        sample = {\n",
        "            \"source_sequence\": torch.tensor(source_sequence),\n",
        "            \"target\": torch.tensor(target),\n",
        "        }\n",
        "        return sample\n",
        "\n",
        "\n",
        "def MyCollator(batch):\n",
        "    source_sequences = pad_sequence(\n",
        "        #we use padding to match the length of the sequences in the same batch\n",
        "        [sample[\"source_sequence\"] for sample in batch], padding_value=token2ind[\"<pad>\"]\n",
        "    )\n",
        "    target = pad_sequence(\n",
        "        [sample[\"target\"] for sample in batch], padding_value=token2ind[\"<pad>\"]\n",
        "    )\n",
        "    return source_sequences, target.reshape(-1)\n",
        "\n",
        "\n",
        "def get_loader(\n",
        "    path_documents,\n",
        "    path_labels=None,\n",
        "    token2ind={},\n",
        "    max_len=512,\n",
        "    batch_size=32,\n",
        "    task=\"language_modeling\",\n",
        "):\n",
        "    dataset = Dataset(\n",
        "        path_documents,\n",
        "        path_labels=path_labels,\n",
        "        token2ind=token2ind,\n",
        "        max_len=512,\n",
        "        task=task,\n",
        "    )\n",
        "    data_loader = DataLoader(\n",
        "        dataset=dataset,\n",
        "        batch_size=batch_size,\n",
        "        shuffle=True,\n",
        "        collate_fn=MyCollator,\n",
        "        pin_memory=True,\n",
        "        drop_last=True,\n",
        "    )\n",
        "    return data_loader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uTns4lHrjUTa"
      },
      "source": [
        "## The Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "4_jwosiLjRsS"
      },
      "outputs": [],
      "source": [
        "def train(\n",
        "    path_data_train,\n",
        "    path_labels_train=None,\n",
        "    path_data_valid=None,\n",
        "    save_interval=-1,\n",
        "    log_interval=5,\n",
        "    task=\"language_modeling\",\n",
        "    batch_size=32,\n",
        "):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    ntokens = len(token2ind)\n",
        "    data_loader = get_loader(\n",
        "        path_data_train,\n",
        "        path_labels_train,\n",
        "        token2ind,\n",
        "        task=task,\n",
        "        batch_size=batch_size,\n",
        "    )\n",
        "\n",
        "    losses = []\n",
        "    for idx, data in enumerate(data_loader): #step 1\n",
        "        optimizer.zero_grad()\n",
        "        src_mask = model.base.generate_square_subsequent_mask(data[0].size(0)).to(\n",
        "            device\n",
        "        )\n",
        "        input = data[0].to(device)\n",
        "        output = model(input, src_mask) #step 2\n",
        "        if task == 'classification':\n",
        "            #last vector only\n",
        "            output = output[-1,:,:] #fill me\n",
        "        output = output.view(-1, output.shape[-1])\n",
        "        target =  data[1].to(device)\n",
        "        target = target.to(device)\n",
        "        loss = criterion(output, target) #fill me, Cross entropy check next cells\n",
        "        #fill me step 3\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 0.5) # prevent exploding gradient\n",
        "        #fill me step 4\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        if idx % log_interval == 0 and idx > 0:\n",
        "            cur_loss = total_loss / log_interval\n",
        "            print(\n",
        "                \"| epoch {:3d} | {:5d}/{:5d} steps | \"\n",
        "                \"loss {:5.5f} | ppl {:8.3f}\".format(\n",
        "                    epoch, idx, len(data_loader), cur_loss, math.exp(cur_loss),\n",
        "                )\n",
        "            )\n",
        "            losses.append(cur_loss)\n",
        "            total_loss = 0\n",
        "    return losses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "pgf6BDB9jUr6"
      },
      "outputs": [],
      "source": [
        "ntokens = len(token2ind) # the size of vocabulary\n",
        "nhid = 200  # the dimension of the feedforward network model in nn.TransformerEncoder\n",
        "nlayers = 4  # the number of nn.TransformerEncoderLayer in nn.TransformerEncoder\n",
        "nhead = 2  # the number of heads in the multiheadattention models\n",
        "dropout = 0  # the dropout value\n",
        "\n",
        "nclasses = 2 # for classification task only\n",
        "\n",
        "model = Model(ntokens, nhead, nhid, nlayers, ntokens, dropout).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "u-OLy4KIkDwf"
      },
      "outputs": [],
      "source": [
        "# optimization paramerters\n",
        "\n",
        "criterion = nn.CrossEntropyLoss(ignore_index=token2ind['<pad>'])\n",
        "lr = 0.0003  # learning rate\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "Bwh3n9xZQy4e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f29bcbd1-a059-4138-b908-9ec12850fd7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-10-31 18:03:11--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/pretraining_subset.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.111.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10146460 (9.7M) [text/plain]\n",
            "Saving to: ‘pretraining_subset.txt.7’\n",
            "\n",
            "pretraining_subset. 100%[===================>]   9.68M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2023-10-31 18:03:11 (205 MB/s) - ‘pretraining_subset.txt.7’ saved [10146460/10146460]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/pretraining_subset.txt\n",
        "path_data_train = \"pretraining_subset.txt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "0m11g4ScjZaR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bea17976-5e3e-4a43-a315-9979ff3d9f93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "| epoch   1 |   500/ 3125 steps | loss 7.31061 | ppl 1496.096\n",
            "| epoch   1 |  1000/ 3125 steps | loss 6.48201 | ppl  653.283\n",
            "| epoch   1 |  1500/ 3125 steps | loss 6.20248 | ppl  493.974\n",
            "| epoch   1 |  2000/ 3125 steps | loss 6.04616 | ppl  422.487\n",
            "| epoch   1 |  2500/ 3125 steps | loss 5.91481 | ppl  370.484\n",
            "| epoch   1 |  3000/ 3125 steps | loss 5.84726 | ppl  346.283\n",
            "| epoch   2 |   500/ 3125 steps | loss 5.52497 | ppl  250.879\n",
            "| epoch   2 |  1000/ 3125 steps | loss 5.46556 | ppl  236.409\n",
            "| epoch   2 |  1500/ 3125 steps | loss 5.42454 | ppl  226.907\n",
            "| epoch   2 |  2000/ 3125 steps | loss 5.41102 | ppl  223.860\n",
            "| epoch   2 |  2500/ 3125 steps | loss 5.38070 | ppl  217.175\n",
            "| epoch   2 |  3000/ 3125 steps | loss 5.36673 | ppl  214.161\n"
          ]
        }
      ],
      "source": [
        "#pretraining on a tiny subset\n",
        "log_interval = 500\n",
        "epochs = 2\n",
        "for epoch in range(1, epochs + 1): #5\n",
        "      train(\n",
        "        path_data_train,\n",
        "        save_interval=-1,\n",
        "        task=\"language_modeling\", # fill me\n",
        "        batch_size=16,\n",
        "        log_interval=log_interval,\n",
        "     )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MeOM1dOvkO4e"
      },
      "source": [
        "## Text Generation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "-BcBC6FSkMH3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c087c178-5b20-4c60-9c55-096ed9d856b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-10-31 18:08:00--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/pretrained_model_4layers.pt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 88093955 (84M) [application/octet-stream]\n",
            "Saving to: ‘pretrained_model_4layers.pt.3’\n",
            "\n",
            "pretrained_model_4l 100%[===================>]  84.01M   348MB/s    in 0.2s    \n",
            "\n",
            "2023-10-31 18:08:09 (348 MB/s) - ‘pretrained_model_4layers.pt.3’ saved [88093955/88093955]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/nn/modules/transformer.py:282: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(f\"enable_nested_tensor is True, but self.use_nested_tensor is False because {why_not_sparsity_fast_path}\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/pretrained_model_4layers.pt\n",
        "\n",
        "model = Model(ntokens, nhead, nhid, nlayers, ntokens).to(device)\n",
        "\n",
        "#load the checkpoint\n",
        "checkpoint = torch.load('pretrained_model_4layers.pt')\n",
        "#load state dict\n",
        "model.load_state_dict(checkpoint['model_state_dict'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "tBRRVsWqlIoQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dc078228-0d16-4e19-efc2-a38cc1d562d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n",
            "--2023-10-31 18:08:14--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/sentencepiece.french.model\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1115362 (1.1M) [application/octet-stream]\n",
            "Saving to: ‘sentencepiece.french.model.3’\n",
            "\n",
            "sentencepiece.frenc 100%[===================>]   1.06M  --.-KB/s    in 0.02s   \n",
            "\n",
            "2023-10-31 18:08:14 (48.6 MB/s) - ‘sentencepiece.french.model.3’ saved [1115362/1115362]\n",
            "\n",
            "['▁Bonjour', '▁les', '▁amis', '!']\n",
            "Bonjour les amis!\n"
          ]
        }
      ],
      "source": [
        "!pip install sentencepiece   # uncomment this if you are using google colab\n",
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/sentencepiece.french.model\n",
        "\n",
        "import sentencepiece as spm\n",
        "\n",
        "s = spm.SentencePieceProcessor(model_file='sentencepiece.french.model') #load sentencepiece model\n",
        "\n",
        "#examples\n",
        "encoded = s.encode_as_pieces(\"Bonjour les amis!\")\n",
        "decoded = s.decode_pieces(encoded)\n",
        "print(encoded)\n",
        "print(decoded)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "TtLlV05pkQI3"
      },
      "outputs": [],
      "source": [
        "def infer_next_token(sent):\n",
        "    model.eval()\n",
        "    sent_pieces = s.encode_as_pieces(sent)\n",
        "    source = [token2ind['<sos>']] + [token2ind[el] for el in sent_pieces] # list of tokens\n",
        "    source = torch.tensor(source).to(device)\n",
        "    source = source.reshape(-1, 1)\n",
        "    src_mask = model.base.generate_square_subsequent_mask(source.size(0)).to(device)\n",
        "    out = model(source, src_mask)\n",
        "    next_token_ind =  torch.argmax(out[-1, :]).item()\n",
        "    return next_token_ind, out\n",
        "\n",
        "def infer_next_tokens(sent, max_len=50):\n",
        "    generated_tokens = []\n",
        "\n",
        "    for _ in range(max_len):\n",
        "        next_token_ind, out = infer_next_token(sent)\n",
        "\n",
        "        # Break if the predicted token is <eos> or <pad>\n",
        "        if next_token_ind == token2ind['<eos>'] or next_token_ind == token2ind['<pad>']:\n",
        "            break\n",
        "\n",
        "        # Decode the predicted token and append it to the generated tokens\n",
        "        next_token = ind2token[next_token_ind]\n",
        "        generated_tokens.append(next_token)\n",
        "\n",
        "        # Update the input sentence for the next iteration\n",
        "        sent += \" \" + next_token\n",
        "\n",
        "    return generated_tokens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "f83Nn5nSly4v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ad28c91-4ccd-4a28-9a23-70aa517480bb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['▁gens',\n",
              " '▁qui',\n",
              " '▁ont',\n",
              " '▁été',\n",
              " '▁très',\n",
              " '▁accueillants',\n",
              " '▁et',\n",
              " '▁sympathiques',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "sent = \"Bonjour les\"\n",
        "infer_next_tokens(sent)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lp7mjVzomoZ3"
      },
      "source": [
        "### Supervised task"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "0K1BZsblmEmx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dff04717-518a-4d48-bc50-3265e3ac6789"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-10-31 18:08:14--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/train.review.spm\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1495960 (1.4M) [text/plain]\n",
            "Saving to: ‘train.review.spm.3’\n",
            "\n",
            "train.review.spm.3  100%[===================>]   1.43M  --.-KB/s    in 0.02s   \n",
            "\n",
            "2023-10-31 18:08:15 (60.3 MB/s) - ‘train.review.spm.3’ saved [1495960/1495960]\n",
            "\n",
            "--2023-10-31 18:08:15--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/train.label\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3200 (3.1K) [text/plain]\n",
            "Saving to: ‘train.label.3’\n",
            "\n",
            "train.label.3       100%[===================>]   3.12K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-10-31 18:08:15 (43.3 MB/s) - ‘train.label.3’ saved [3200/3200]\n",
            "\n",
            "--2023-10-31 18:08:15--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/test.review.spm\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1864544 (1.8M) [text/plain]\n",
            "Saving to: ‘test.review.spm.3’\n",
            "\n",
            "test.review.spm.3   100%[===================>]   1.78M  --.-KB/s    in 0.02s   \n",
            "\n",
            "2023-10-31 18:08:15 (72.1 MB/s) - ‘test.review.spm.3’ saved [1864544/1864544]\n",
            "\n",
            "--2023-10-31 18:08:15--  https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/test.label\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 4000 (3.9K) [text/plain]\n",
            "Saving to: ‘test.label.3’\n",
            "\n",
            "test.label.3        100%[===================>]   3.91K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-10-31 18:08:15 (58.7 MB/s) - ‘test.label.3’ saved [4000/4000]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/train.review.spm\n",
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/train.label\n",
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/test.review.spm\n",
        "!wget https://raw.githubusercontent.com/moussaKam/transfer_learning_transformers/main/cls-books/test.label\n",
        "\n",
        "path_data_train = \"train.review.spm\"\n",
        "path_labels_train = \"train.label\"\n",
        "\n",
        "path_data_valid = \"test.review.spm\"\n",
        "path_labels_valid = \"test.label\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "_MLfvjiom2SL"
      },
      "outputs": [],
      "source": [
        "# a function to evaluate the validation accuracy of the model.\n",
        "def evaluate_accuracy(data_loader):\n",
        "\n",
        "  model.eval()\n",
        "\n",
        "  num_correct = 0\n",
        "  num_samples = 0\n",
        "\n",
        "  with torch.no_grad():\n",
        "    for src, tgt in data_loader:\n",
        "      src = src.to(device)\n",
        "      tgt = tgt.to(device)\n",
        "\n",
        "      src_mask = model.base.generate_square_subsequent_mask(src.shape[0]).to(device)\n",
        "      output = model(src, src_mask)\n",
        "\n",
        "      output = output[-1,:,:] # get last time step output\n",
        "      pred = output.argmax(dim=-1)\n",
        "\n",
        "      num_correct += (pred == tgt).sum().item()\n",
        "      num_samples += pred.shape[0]\n",
        "\n",
        "  acc = num_correct / num_samples\n",
        "\n",
        "  return acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "qzmx7T7xoa6v"
      },
      "outputs": [],
      "source": [
        "#save the base model to be loaded later in the fine-tuning phase\n",
        "torch.save({\"model_state_dict\": model.base.state_dict(),}, \"pretrained_model_4layers_no_class_head.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "i-xclMCpnVpw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "21d31843-77a7-4693-dd04-8dd920f25f48"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=====Trainig FROM SCRATCH======\n",
            "| epoch   1 |    50/  200 steps | loss 0.80782 | ppl    2.243\n",
            "| epoch   1 |   100/  200 steps | loss 0.73078 | ppl    2.077\n",
            "| epoch   1 |   150/  200 steps | loss 0.71211 | ppl    2.038\n",
            "| epoch   2 |    50/  200 steps | loss 0.71668 | ppl    2.048\n",
            "| epoch   2 |   100/  200 steps | loss 0.61723 | ppl    1.854\n",
            "| epoch   2 |   150/  200 steps | loss 0.60904 | ppl    1.839\n",
            "| epoch   3 |    50/  200 steps | loss 0.36122 | ppl    1.435\n",
            "| epoch   3 |   100/  200 steps | loss 0.49037 | ppl    1.633\n",
            "| epoch   3 |   150/  200 steps | loss 0.29090 | ppl    1.338\n",
            "| epoch   4 |    50/  200 steps | loss 0.19038 | ppl    1.210\n",
            "| epoch   4 |   100/  200 steps | loss 0.16255 | ppl    1.177\n",
            "| epoch   4 |   150/  200 steps | loss 0.14821 | ppl    1.160\n",
            "| epoch   5 |    50/  200 steps | loss 0.05509 | ppl    1.057\n",
            "| epoch   5 |   100/  200 steps | loss 0.03155 | ppl    1.032\n",
            "| epoch   5 |   150/  200 steps | loss 0.04882 | ppl    1.050\n",
            "| epoch   6 |    50/  200 steps | loss 0.04361 | ppl    1.045\n",
            "| epoch   6 |   100/  200 steps | loss 0.01232 | ppl    1.012\n",
            "| epoch   6 |   150/  200 steps | loss 0.02076 | ppl    1.021\n",
            "| epoch   7 |    50/  200 steps | loss 0.00011 | ppl    1.000\n",
            "| epoch   7 |   100/  200 steps | loss 0.00281 | ppl    1.003\n",
            "| epoch   7 |   150/  200 steps | loss 0.02373 | ppl    1.024\n",
            "| epoch   8 |    50/  200 steps | loss 0.00002 | ppl    1.000\n",
            "| epoch   8 |   100/  200 steps | loss 0.00002 | ppl    1.000\n",
            "| epoch   8 |   150/  200 steps | loss 0.02791 | ppl    1.028\n",
            "| epoch   9 |    50/  200 steps | loss 0.00003 | ppl    1.000\n",
            "| epoch   9 |   100/  200 steps | loss 0.00014 | ppl    1.000\n",
            "| epoch   9 |   150/  200 steps | loss 0.00002 | ppl    1.000\n",
            "| epoch  10 |    50/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  10 |   100/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  10 |   150/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  11 |    50/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  11 |   100/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  11 |   150/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  12 |    50/  200 steps | loss 0.00073 | ppl    1.001\n",
            "| epoch  12 |   100/  200 steps | loss 0.00029 | ppl    1.000\n",
            "| epoch  12 |   150/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  13 |    50/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  13 |   100/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  13 |   150/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  14 |    50/  200 steps | loss 0.01044 | ppl    1.010\n",
            "| epoch  14 |   100/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch  14 |   150/  200 steps | loss 0.04008 | ppl    1.041\n",
            "| epoch  15 |    50/  200 steps | loss 0.03891 | ppl    1.040\n",
            "| epoch  15 |   100/  200 steps | loss 0.02789 | ppl    1.028\n",
            "| epoch  15 |   150/  200 steps | loss 0.00005 | ppl    1.000\n",
            "\n",
            "=====PRETRAINED MODEL======\n",
            "| epoch   1 |    50/  200 steps | loss 0.09865 | ppl    1.104\n",
            "| epoch   1 |   100/  200 steps | loss 0.00117 | ppl    1.001\n",
            "| epoch   1 |   150/  200 steps | loss 0.00098 | ppl    1.001\n",
            "| epoch   2 |    50/  200 steps | loss 0.01130 | ppl    1.011\n",
            "| epoch   2 |   100/  200 steps | loss 0.01118 | ppl    1.011\n",
            "| epoch   2 |   150/  200 steps | loss 0.02041 | ppl    1.021\n",
            "| epoch   3 |    50/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch   3 |   100/  200 steps | loss 0.00040 | ppl    1.000\n",
            "| epoch   3 |   150/  200 steps | loss 0.00004 | ppl    1.000\n",
            "| epoch   4 |    50/  200 steps | loss 0.00001 | ppl    1.000\n",
            "| epoch   4 |   100/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch   4 |   150/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch   5 |    50/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch   5 |   100/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch   5 |   150/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch   6 |    50/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch   6 |   100/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch   6 |   150/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch   7 |    50/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch   7 |   100/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch   7 |   150/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch   8 |    50/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch   8 |   100/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch   8 |   150/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch   9 |    50/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch   9 |   100/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch   9 |   150/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  10 |    50/  200 steps | loss 0.08698 | ppl    1.091\n",
            "| epoch  10 |   100/  200 steps | loss 0.14508 | ppl    1.156\n",
            "| epoch  10 |   150/  200 steps | loss 0.14533 | ppl    1.156\n",
            "| epoch  11 |    50/  200 steps | loss 0.04279 | ppl    1.044\n",
            "| epoch  11 |   100/  200 steps | loss 0.01925 | ppl    1.019\n",
            "| epoch  11 |   150/  200 steps | loss 0.05998 | ppl    1.062\n",
            "| epoch  12 |    50/  200 steps | loss 0.01218 | ppl    1.012\n",
            "| epoch  12 |   100/  200 steps | loss 0.03585 | ppl    1.036\n",
            "| epoch  12 |   150/  200 steps | loss 0.04703 | ppl    1.048\n",
            "| epoch  13 |    50/  200 steps | loss 0.00041 | ppl    1.000\n",
            "| epoch  13 |   100/  200 steps | loss 0.00080 | ppl    1.001\n",
            "| epoch  13 |   150/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  14 |    50/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  14 |   100/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  14 |   150/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  15 |    50/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  15 |   100/  200 steps | loss 0.00000 | ppl    1.000\n",
            "| epoch  15 |   150/  200 steps | loss 0.00000 | ppl    1.000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from_scratch_settings = [True, False]\n",
        "\n",
        "from_scratch_valid_acc = []\n",
        "pretrained_valid_acc = []\n",
        "lr = 0.0001\n",
        "\n",
        "for from_scratch in from_scratch_settings:\n",
        "    model = Model(ntokens, nhead, nhid, nlayers, 2, dropout).to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    if not from_scratch:\n",
        "        print(\"=====PRETRAINED MODEL======\")\n",
        "        #load checkpoint\n",
        "        checkpoint = torch.load(\"pretrained_model_4layers_no_class_head.pt\")\n",
        "        #load state dict\n",
        "        model.base.load_state_dict(checkpoint['model_state_dict'])\n",
        "    else:\n",
        "        print(\"=====Trainig FROM SCRATCH======\")\n",
        "    epochs = 15\n",
        "    for epoch in range(1, epochs + 1):\n",
        "        train(\n",
        "            path_data_train,\n",
        "            path_labels_train,\n",
        "            save_interval=-1,\n",
        "            task='classification',\n",
        "            batch_size=8,\n",
        "            log_interval=50,\n",
        "        )\n",
        "        acc = evaluate_accuracy(\n",
        "            get_loader(\n",
        "                path_data_valid,\n",
        "                path_labels_valid,\n",
        "                token2ind=token2ind,\n",
        "                batch_size=20,\n",
        "                task='classification',\n",
        "            )\n",
        "        )\n",
        "        if from_scratch:\n",
        "            from_scratch_valid_acc.append(acc)\n",
        "        else:\n",
        "            pretrained_valid_acc.append(acc)\n",
        "    print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "RCpBIdTHojm6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "outputId": "e6b3358a-70f5-4b9b-a578-902b9f1bf4d5"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "#Visualize the accuracy\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(range(1,len(from_scratch_valid_acc)+1), from_scratch_valid_acc, label='accuracy from scratch' )\n",
        "plt.plot(range(1,len(pretrained_valid_acc)+1), pretrained_valid_acc, label='accuracy from pretrained')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylabel('accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.6.15 ('altegrad')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.15"
    },
    "vscode": {
      "interpreter": {
        "hash": "1f3cfdeab8dd8f9900bd16266619de191cf0f5e09365d74b1fba1714dce58066"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}